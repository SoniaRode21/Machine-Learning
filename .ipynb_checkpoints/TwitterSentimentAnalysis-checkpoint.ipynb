{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "The following code uses movie_reviews data from nltk.corpus. The data contains files with movie reviews and \n",
    "their corresponding labels(positive or negative)\n",
    "It does text preprocessing such as removing stop words and tokenization.\n",
    "After preprocessing different classifiers like Naive Bayesian classifier,SVC_classifier,BernoulliNB_classifier,\n",
    "SGDClassifier_classifier,LogisticRegression_classifier are implemented.\n",
    "Finally a aggregator classifer which outputs the most voted label and its confidence is implemented.\n",
    "\n",
    "\n",
    "__author__='Soniya Rode'\n",
    "__citation__=\"pythonprogramming\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initalise the stop words set and tokenizer to remove punctuations.\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data from the files\n",
    "lines=[]\n",
    "posfile= open(\"positive.txt\",\"r\",encoding='latin-1').read()\n",
    "for line in posfile.split('\\n'):\n",
    "    lines.append((line,\"positive\"))\n",
    "    \n",
    "print(lines[0])\n",
    "negfile = open(\"negative.txt\",\"r\",encoding='latin-1').read()\n",
    "for line in negfile.split('\\n'):\n",
    "    lines.append((line,\"negative\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Get all words in the movie reviews\n",
    "words = []\n",
    "\n",
    "pos_words = word_tokenize(posfile)\n",
    "neg_words = word_tokenize(negfile)\n",
    "\n",
    "for w in pos_words :\n",
    "    if tokenizer.tokenize(w) and w not in stopwords:\n",
    "        words.append(w.lower())\n",
    "        #print(words)\n",
    "for w in neg_words :\n",
    "    if tokenizer.tokenize(w) and w not in stopwords:\n",
    "        words.append(w.lower())\n",
    "            \n",
    "\n",
    "#Get frequencies of all words\n",
    "words = nltk.FreqDist(words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get top most 10 common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the top 4000 common words\n",
    "commonWords=list(words.keys())[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to return boolean value for words from the review which are amongst the most common words.\n",
    "#Return True if the word in the review is among the top 4000 words.\n",
    "def check_commonWords(words):\n",
    "    words = set(words)\n",
    "    listOfCommonWords = {}\n",
    "    for w in commonWords:\n",
    "        listOfCommonWords[w] = (w in words)\n",
    "\n",
    "    return listOfCommonWords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now\n",
    "featuresets = [(check_commonWords(rev), category) for (rev, category) in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(featuresets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into training and testing\n",
    "training_set = featuresets[:10000]\n",
    "\n",
    "# set that we'll test against.\n",
    "testing_set = featuresets[10000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use NLTK's Naive Bayes classifier \n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"accuracy:\",(nltk.classify.accuracy(classifier, testing_set))*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.show_most_informative_features(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the classifier\n",
    "Pickle_classifier = open(\"naivebayes.pickle\",\"wb\")\n",
    "pickle.dump(classifier, Pickle_classifier)\n",
    "Pickle_classifier.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Using sklearn classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression Classifier\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression(solver='lbfgs'))\n",
    "LogisticRegression_classifier.train(training_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stochastic gradient descent (SGD) classifier\n",
    "SGDClassifier_classifier = SklearnClassifier(SGDClassifier( max_iter=1000))\n",
    "SGDClassifier_classifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support Vector machine Classifier\n",
    "SVC_classifier = SklearnClassifier(SVC(gamma='auto'))\n",
    "SVC_classifier.train(training_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(training_set)\n",
    "print(\"BernoulliNB_classifier accuracy percent:\", (nltk.classify.accuracy(BernoulliNB_classifier, testing_set))*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classifier Accuracies:\n",
    "print(\"Classifier accuracies :\")\n",
    "print(\"Naive Bayes Classifier accuracy:\",(nltk.classify.accuracy(classifier, testing_set))*100)\n",
    "print(\"LogisticRegression_classifier accuracy:\", (nltk.classify.accuracy(LogisticRegression_classifier, testing_set))*100)\n",
    "\n",
    "print(\"SGDClassifier_classifier accuracy:\", (nltk.classify.accuracy(SGDClassifier_classifier, testing_set))*100)\n",
    "print(\"SVC_classifier accuracy:\", (nltk.classify.accuracy(SVC_classifier, testing_set))*100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Aggregated Classifier takes different classifiers as input. To classify it takes vote from each classifier, and \n",
    "returns the class label with most number of votes(mode)\n",
    "The get_confidence method returns the confidence on the vote(class label)\n",
    "\n",
    "The get_confidence uses mode method from statistics which raisies statistics.StatisticsError\n",
    "statistics.StatisticsError: no unique mode; found 2 equally common values \n",
    "Since number of classifiers used in uneven, this error is avoided.\n",
    "'''\n",
    "class AggregatedClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "    def classify(self, features):\n",
    "            votes = []\n",
    "            for classifier in self._classifiers:\n",
    "                votes.append(classifier.classify(features))\n",
    "            return mode(votes)\n",
    "    def get_confidence(self, features):\n",
    "        votes = []\n",
    "        for classifier in self._classifiers:\n",
    "            votes.append(classifier.classify(features))\n",
    "\n",
    "         \n",
    "        confidence = votes.count(mode(votes)) / len(votes)\n",
    "        return confidence\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_classifier = AggregatedClassifier(classifier,SVC_classifier,BernoulliNB_classifier,SGDClassifier_classifier,LogisticRegression_classifier)\n",
    "\n",
    "#print(\"voted_classifier accuracy percent:\", (nltk.classify.accuracy(voted_classifier, testing_set))*100)\n",
    "for i in range(20):\n",
    "    print(\"Predicted Class label:\", agg_classifier.classify(testing_set[i][0]), \"Confidence %:\",agg_classifier.get_confidence(testing_set[i][0])*100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
